{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom tqdm import tqdm\nimport os\nimport cv2\nimport tensorflow as tf\nimport matplotlib.pyplot  as plt","execution_count":4,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_label_csv = pd.read_csv('../input/machinelearning412-skincancerclassification/Train.csv')\ntest_label_csv  = pd.read_csv('../input/machinelearning412-skincancerclassification/Test.csv')\nDATA_DIR = '../input/machinelearning412-skincancerclassification/Data_SkinCancer/Data_SkinCancer'\nIMG_SIZE = 50","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data  = []\ntrain_label = []\ntest_data   = []\ntest_label  = []\ndef prepare_data():\n    for img in tqdm(os.listdir(DATA_DIR)):\n        img_num = int(img[6:-4])-1\n        if img_num < 10000:\n            img_label = train_label_csv.iloc[(img_num),1]\n            path = os.path.join(DATA_DIR,img)\n            img_array = cv2.imread(path)    \n            resized_array = cv2.resize(img_array,(IMG_SIZE,IMG_SIZE))\n            train_data.append([resized_array])\n            train_label.append(img_label)\n        else:\n            img_label = test_label_csv.iloc[(img_num-10000),1]            \n            path = os.path.join(DATA_DIR,img)\n            img_array = cv2.imread(path)    \n            resized_array = cv2.resize(img_array,(IMG_SIZE,IMG_SIZE))\n            test_data.append([resized_array])\n            test_label.append(img_label)\n        \nprepare_data()","execution_count":3,"outputs":[{"output_type":"stream","text":"100%|██████████| 15000/15000 [03:20<00:00, 74.64it/s]\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = train_data[:9500]\ny_train = train_label[:9500]\nX_val = train_data[9500:]\ny_val = train_label[9500:]\nlen(X_val)\n\nX_train = np.array(X_train).reshape(-1, IMG_SIZE, IMG_SIZE, 3)\nX_val = np.array(X_val).reshape(-1, IMG_SIZE, IMG_SIZE, 3)\ny_train=np.array(y_train)\ny_val=np.array(y_val)","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = tf.keras.models.Sequential([\n  tf.keras.layers.Conv2D(filters=64, kernel_size=3, strides=2, activation='relu', input_shape=(IMG_SIZE,IMG_SIZE,3)),\n  tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=1, padding='same'),\n  tf.keras.layers.Conv2D(filters=32, kernel_size=3, strides=1, activation='relu'),\n  tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=1, padding='same'),\n  tf.keras.layers.Flatten(),\n  tf.keras.layers.Dense(10, activation='softmax')\n])","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\nmodel.fit(X_train, y_train, validation_data=(X_val, y_val), batch_size=32, epochs=10)","execution_count":15,"outputs":[{"output_type":"stream","text":"Train on 9500 samples, validate on 500 samples\nEpoch 1/10\n9500/9500 [==============================] - 17s 2ms/sample - loss: 2.5185 - accuracy: 0.4464 - val_loss: 1.2759 - val_accuracy: 0.4720\nEpoch 2/10\n9500/9500 [==============================] - 17s 2ms/sample - loss: 1.3031 - accuracy: 0.4968 - val_loss: 1.1955 - val_accuracy: 0.5040\nEpoch 3/10\n9500/9500 [==============================] - 17s 2ms/sample - loss: 1.2559 - accuracy: 0.5060 - val_loss: 1.2074 - val_accuracy: 0.4940\nEpoch 4/10\n9500/9500 [==============================] - 18s 2ms/sample - loss: 1.2170 - accuracy: 0.5180 - val_loss: 1.1791 - val_accuracy: 0.5080\nEpoch 5/10\n9500/9500 [==============================] - 17s 2ms/sample - loss: 1.1625 - accuracy: 0.5346 - val_loss: 1.1689 - val_accuracy: 0.5300\nEpoch 6/10\n9500/9500 [==============================] - 17s 2ms/sample - loss: 1.1453 - accuracy: 0.5444 - val_loss: 1.1627 - val_accuracy: 0.5580\nEpoch 7/10\n9500/9500 [==============================] - 17s 2ms/sample - loss: 1.1479 - accuracy: 0.5488 - val_loss: 1.1454 - val_accuracy: 0.5360\nEpoch 8/10\n9500/9500 [==============================] - 17s 2ms/sample - loss: 1.1318 - accuracy: 0.5456 - val_loss: 1.1310 - val_accuracy: 0.5360\nEpoch 9/10\n9500/9500 [==============================] - 17s 2ms/sample - loss: 1.1339 - accuracy: 0.5518 - val_loss: 1.2247 - val_accuracy: 0.5020\nEpoch 10/10\n9500/9500 [==============================] - 17s 2ms/sample - loss: 1.1230 - accuracy: 0.5535 - val_loss: 1.1394 - val_accuracy: 0.5580\n","name":"stdout"},{"output_type":"execute_result","execution_count":15,"data":{"text/plain":"<tensorflow.python.keras.callbacks.History at 0x7f75fa7883d0>"},"metadata":{}}]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}